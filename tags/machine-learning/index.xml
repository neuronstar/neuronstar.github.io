<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on NeuronStar</title><link>https://neuronstar.github.io/tags/machine-learning/</link><description>Recent content in Machine Learning on NeuronStar</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Sat, 11 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://neuronstar.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Graph Neural Networks: Theoretical Motivations</title><link>https://neuronstar.github.io/cpe/25.gnn-2/</link><pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/25.gnn-2/</guid><description>We have changed the time!</description></item><item><title>Graph Neural Networks: Theoretical Motivations (Part 2)</title><link>https://neuronstar.github.io/cpe/26.gnn-3/</link><pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/26.gnn-3/</guid><description>We discussed the first section of Chapter 7. In this event, we will continue discussing chapter 7 of Hamilton1.
In this chapter, we will visit some of the theoretical underpinnings of graph neu- ral networks (GNNs). One of the most intriguing aspects of GNNs is that they were independently developed from distinct theoretical motivations.
Click here for an interactive widget.
Hamilton2020 Hamilton WL.</description></item><item><title>Graph Convolutional Matrix Completion</title><link>https://neuronstar.github.io/cpe/27.graph-convolutional-matrix-completion/</link><pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/27.graph-convolutional-matrix-completion/</guid><description>Our topic for this session is Graph Convolutional Matrix Completion (arXiv:1706.02263).
Abstract
Abstract of Graph Convolutional Matrix Completion (arXiv:1706.02263):
We consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph.</description></item><item><title>Multivariate Time-series Forecasting Using GNN</title><link>https://neuronstar.github.io/cpe/28.gnn-time-series-forecasting/</link><pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/28.gnn-time-series-forecasting/</guid><description>Our topic for this session is Spectral Temporal Graph Neural Network for multivariate time-series forecasting (arXiv:2103.07719).
Abstract
Abstract of Spectral Temporal Graph Neural Network for multivariate time-series forecasting (arXiv:2103.07719):
Multivariate time-series forecasting plays a crucial rolein many real-world ap-plications. It is a challenging problem as one needs to consider both intra-seriestemporal correlations and inter-series correlations simultaneously. Recently, there have been multiple works trying to capture both correlations, but most, if not allof them only capture temporal correlations in the time domain and resort to pre-defined priors as inter-series relationships.</description></item><item><title>Foundations of Machine Learning</title><link>https://neuronstar.github.io/projects/ml-foundations/</link><pubDate>Sun, 03 May 2020 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/projects/ml-foundations/</guid><description>Dive deep into the foundations of machine learning.</description></item><item><title>The Elements of Statistical Learning Reading Club</title><link>https://neuronstar.github.io/projects/esl/</link><pubDate>Mon, 27 Apr 2020 13:22:46 +0200</pubDate><guid>https://neuronstar.github.io/projects/esl/</guid><description>Read the book</description></item></channel></rss>