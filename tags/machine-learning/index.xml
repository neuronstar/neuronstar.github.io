<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on NeuronStar</title><link>https://neuronstar.github.io/tags/machine-learning/</link><description>Recent content in Machine Learning on NeuronStar</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Sat, 09 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://neuronstar.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Graph Neural Networks: Theoretical Motivations</title><link>https://neuronstar.github.io/cpe/25.gnn-2/</link><pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/25.gnn-2/</guid><description>We have changed the time!</description></item><item><title>Graph Neural Networks: Theoretical Motivations (Part 2)</title><link>https://neuronstar.github.io/cpe/26.gnn-3/</link><pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/26.gnn-3/</guid><description>We discussed the first section of Chapter 7. In this event, we will continue discussing chapter 7 of Hamilton1.
In this chapter, we will visit some of the theoretical underpinnings of graph neu- ral networks (GNNs). One of the most intriguing aspects of GNNs is that they were independently developed from distinct theoretical motivations.
Click here for an interactive widget.
Hamilton2020 Hamilton WL.</description></item><item><title>Graph Convolutional Matrix Completion</title><link>https://neuronstar.github.io/cpe/27.graph-convolutional-matrix-completion/</link><pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/27.graph-convolutional-matrix-completion/</guid><description>Our topic for this session is Graph Convolutional Matrix Completion (arXiv:1706.02263).
Abstract
Abstract of Graph Convolutional Matrix Completion (arXiv:1706.02263):
We consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph.</description></item><item><title>Multivariate Time-series Forecasting Using GNN</title><link>https://neuronstar.github.io/cpe/28.gnn-time-series-forecasting/</link><pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/28.gnn-time-series-forecasting/</guid><description>Our topic for this session is Spectral Temporal Graph Neural Network for multivariate time-series forecasting (arXiv:2103.07719).
Abstract
Abstract of Spectral Temporal Graph Neural Network for multivariate time-series forecasting (arXiv:2103.07719):
Multivariate time-series forecasting plays a crucial rolein many real-world ap-plications. It is a challenging problem as one needs to consider both intra-seriestemporal correlations and inter-series correlations simultaneously. Recently, there have been multiple works trying to capture both correlations, but most, if not allof them only capture temporal correlations in the time domain and resort to pre-defined priors as inter-series relationships.</description></item><item><title>Hamilton WL. Graph Representation Learning. Chapter 8</title><link>https://neuronstar.github.io/cpe/29.hamilton-traditional-graph-generation-approaches/</link><pubDate>Sat, 05 Feb 2022 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/29.hamilton-traditional-graph-generation-approaches/</guid><description>Our topic for this session is Chapter 8 of Hamilton WL. Graph Representation Learning: Traditional GraphGeneration Approaches.
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Hamilton WL. Graph Representation Learning. Chapter 8 (2)</title><link>https://neuronstar.github.io/cpe/30.hamilton-traditional-graph-generation-approaches-2/</link><pubDate>Fri, 18 Feb 2022 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/30.hamilton-traditional-graph-generation-approaches-2/</guid><description>We will wrap up Chapter 8 of Hamilton WL. Graph Representation Learning: Graph Generation.
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Uncertainty in Deep Learning</title><link>https://neuronstar.github.io/cpe/31.uncertaintyt-in-deep-learning/</link><pubDate>Sat, 26 Feb 2022 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/31.uncertaintyt-in-deep-learning/</guid><description>Topic: uncertainty in deep learning
References:
Gawlikowski, J. et al. A Survey of Uncertainty in Deep Neural Networks. Arxiv (2021). Jospin, L. V., Buntine, W., Boussaid, F., Laga, H. &amp;amp; Bennamoun, M. Hands-on Bayesian Neural Networks &amp;ndash; a Tutorial for Deep Learning Users. Arxiv (2020). Gal, Yarin. &amp;ldquo;Uncertainty in deep learning.&amp;rdquo; (2016): 3. Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.</description></item><item><title>Causal Inference</title><link>https://neuronstar.github.io/cpe/35.causal-inference/</link><pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/35.causal-inference/</guid><description>Alexa will lead a discussion on causal inference.
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Counterfactual Explanation in Multivariate Time Series</title><link>https://neuronstar.github.io/cpe/34.counterfactual-prediction-multivariate-time-series/</link><pubDate>Tue, 12 Apr 2022 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/34.counterfactual-prediction-multivariate-time-series/</guid><description>Ates E, Aksar B, Leung VJ, Coskun AK. Counterfactual Explanations for Machine Learning on Multivariate Time Series Data. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2008.10781
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Review of Time Series Forecasting</title><link>https://neuronstar.github.io/cpe/33.review-of-timeseries-2/</link><pubDate>Tue, 12 Apr 2022 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/33.review-of-timeseries-2/</guid><description>Lim B, Zohren S. Time Series Forecasting With Deep Learning: A Survey. arXiv [stat.ML]. 2020. Available: http://arxiv.org/abs/2004.13408
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Conformal Time Series Forecasting</title><link>https://neuronstar.github.io/cpe/32.review-of-timeseries/</link><pubDate>Thu, 10 Mar 2022 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/32.review-of-timeseries/</guid><description>We start our new journey on time series by sharing and discussing two review papers:
Lim B, Zohren S. Time Series Forecasting With Deep Learning: A Survey. arXiv [stat.ML]. 2020. Available: http://arxiv.org/abs/2004.13408 Gneiting T, Katzfuss M. Probabilistic Forecasting. Annu Rev Stat Appl. 2014;1: 125â€“151. doi:10.1146/annurev-statistics-062713-085831 (pdf) Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Evaluating time series forecasting models</title><link>https://neuronstar.github.io/cpe/36.evaluating-forecasting-models/</link><pubDate>Fri, 10 Jun 2022 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/36.evaluating-forecasting-models/</guid><description>Our topic for this session is
Cerqueira V, Torgo L, Mozetic I. Evaluating time series forecasting models: An empirical study on performance estimation methods. arXiv [cs.LG]. 2019. Available: http://arxiv.org/abs/1905.11744
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>DeepAR</title><link>https://neuronstar.github.io/cpe/37.deepar/</link><pubDate>Fri, 10 Jun 2022 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/37.deepar/</guid><description>Topic: DeepAR.
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Temporal Fusion Transformer</title><link>https://neuronstar.github.io/cpe/38.tft/</link><pubDate>Sat, 09 Jul 2022 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/38.tft/</guid><description>Lim B, Arik SO, Loeff N, Pfister T. Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting. In: arXiv.org [Internet]. 19 Dec 2019 [cited 9 Jul 2022]. Available: https://arxiv.org/abs/1912.09363
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Inferring causal impact using Bayesian structural time-series models</title><link>https://neuronstar.github.io/cpe/tbd.causal-impact-bayesian-structural-ts-models/</link><pubDate>Sat, 21 May 2022 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/tbd.causal-impact-bayesian-structural-ts-models/</guid><description>Our topic for this session is Inferring causal impact using Bayesian structural time-series models (arXiv:1506.00356).
Abstract
Abstract of Inferring causal impact using Bayesian structural time-series models (arXiv:1506.00356):
An important problem in econometrics and marketing is to infer the causal impact that a designed market intervention has exerted on an outcome metric over time. This paper proposes to infer causal impact on the basis of a diffusion-regression state-space model that predicts the counterfactual market response in a synthetic control that would have occurred had no intervention taken place.</description></item><item><title>Foundations of Machine Learning</title><link>https://neuronstar.github.io/projects/ml-foundations/</link><pubDate>Sun, 03 May 2020 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/projects/ml-foundations/</guid><description>Dive deep into the foundations of machine learning.</description></item><item><title>The Elements of Statistical Learning Reading Club</title><link>https://neuronstar.github.io/projects/esl/</link><pubDate>Mon, 27 Apr 2020 13:22:46 +0200</pubDate><guid>https://neuronstar.github.io/projects/esl/</guid><description>Read the book</description></item></channel></rss>