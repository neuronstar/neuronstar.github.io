<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Graph Neural Networks on NeuronStar</title><link>https://neuronstar.github.io/tags/graph-neural-networks/</link><description>Recent content in Graph Neural Networks on NeuronStar</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Sat, 11 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://neuronstar.github.io/tags/graph-neural-networks/index.xml" rel="self" type="application/rss+xml"/><item><title>Graph Neural Networks: Theoretical Motivations</title><link>https://neuronstar.github.io/cpe/25.gnn-2/</link><pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/25.gnn-2/</guid><description>We have changed the time!</description></item><item><title>Graph Neural Networks: Theoretical Motivations (Part 2)</title><link>https://neuronstar.github.io/cpe/26.gnn-3/</link><pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/26.gnn-3/</guid><description>We discussed the first section of Chapter 7. In this event, we will continue discussing chapter 7 of Hamilton1.
In this chapter, we will visit some of the theoretical underpinnings of graph neu- ral networks (GNNs). One of the most intriguing aspects of GNNs is that they were independently developed from distinct theoretical motivations.
Click here for an interactive widget.
Hamilton2020 Hamilton WL.</description></item><item><title>Graph Convolutional Matrix Completion</title><link>https://neuronstar.github.io/cpe/27.graph-convolutional-matrix-completion/</link><pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/27.graph-convolutional-matrix-completion/</guid><description>Our topic for this session is Graph Convolutional Matrix Completion (arXiv:1706.02263).
Abstract
Abstract of Graph Convolutional Matrix Completion (arXiv:1706.02263):
We consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph.</description></item></channel></rss>