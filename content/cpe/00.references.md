---
title: "References for Probability Estimation Club"
description: ""
date: 2020-12-12
author: LM
summary: "A list of references for our online discussions."
tags:
  - Bayesian
  - Least Squares
  - Bootstrap
  - Maximum Likelihood
  - Bayesian
  - Normalizing Flow
references:
  - name: "Trevor Hastie, Robert Tibshirani, J. F. (2004). The Elements of Statistical Learning (Vol. 99, Issue 466). Springer Science & Business Media."
    link: "https://web.stanford.edu/~hastie/ElemStatLearn/"
  - name: "Christpher M. Bishop. (2006). Pattern Recognition and Machine Learning."
    link: "https://doi.org/978-0387-31073-2"
weight: 0
links:
  - projects/conditional-probability-estimation
---

This is Not a Comprehensive List. Please also see the references from each event.

{{< e "cpe" >}}


## Basics

- [Trevor Hastie, Robert Tibshirani, J. F. (2004). The Elements of Statistical Learning (Vol. 99, Issue 466). Springer Science & Business Media.](https://web.stanford.edu/~hastie/ElemStatLearn/)
- [Christpher M. Bishop. (2006). Pattern Recognition and Machine Learning.](https://doi.org/978-0387-31073-2)




### Normalizing Flow

- [Variational Inference with Normalizing Flows](https://arxiv.org/pdf/1505.05770.pdf)
- [Kobyzev, I., Prince, S., & Brubaker, M. (2020). Normalizing Flows: An Introduction and Review of Current Methods. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1–1.](https://doi.org/10.1109/TPAMI.2020.2992934)
- [Gregor, K., Danihelka, I., Mnih, A., Blundell, C., & Wierstra, D. (2014). Deep autoregressive networks. 31st International Conference on Machine Learning, ICML 2014, 4, 2991–3000.](https://arxiv.org/abs/1310.8499)
- [Improving Variational Inference with Inverse Autoregressive Flow](https://arxiv.org/abs/1606.04934)
- [MADE: Masked Autoencoder for Distribution Estimation](https://arxiv.org/abs/1502.03509)
- [Masked Autoregressive Flow for Density Estimation](https://arxiv.org/abs/1705.07057)


- [Deep Generative Modelling: A Comparative Review of VAEs, GANs, Normalizing Flows, Energy-Based and Autoregressive Models](https://arxiv.org/abs/2103.04922)


## Energy-based Models

- [Pytorch Deep Learning Lectures](https://atcold.github.io/pytorch-Deep-Learning/en/week07/07-1/)
- [Pytorch Deep Learning Slides](https://drive.google.com/file/d/1z8Dz1YtkOEJpU-gh5RIjORs3GGqkYJQa/view)
- [A high-bias, low-variance introduction to Machine Learning for physicists](https://arxiv.org/abs/1803.08823)


## ML Connections to Biological Networks

- [Millidge B, Tschantz A, Buckley CL. Predictive Coding Approximates Backprop along Arbitrary Computation Graphs. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2006.04182](https://arxiv.org/abs/2006.04182)


## Graph Neural Networks


- [Hamilton WL. Graph representation learning. Synth lect artif intell mach learn. 2020;14: 1–159. doi:10.2200/s01045ed1v01y202009aim046](https://www.morganclaypool.com/doi/10.2200/S01045ED1V01Y202009AIM046)



