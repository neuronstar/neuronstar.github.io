<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.68.3"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>21.Asynchronous Firing | NeuronStar | NeuronStar</title><meta name=author content="OctoMiao"><meta property="og:title" content="21.Asynchronous Firing"><meta property="og:description" content="Asynchronous firing of homogeneous network"><meta property="og:type" content="article"><meta property="og:url" content="https://neuronstar.github.io/snm/21.asynchronous-firing/"><meta property="article:published_time" content="2016-10-14T00:00:00+00:00"><meta property="article:modified_time" content="2016-10-14T00:00:00+00:00"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-61051776-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link rel=canonical href=https://neuronstar.github.io/snm/21.asynchronous-firing/><link rel="shortcut icon" type=image/png href=/logos/logo-square.png><link rel=stylesheet href=/css/bulma.css><link rel=stylesheet href=/css/bulma-divider.min.css><link rel=stylesheet href=/assets/css/bulma-ribbon.min.css><link rel=stylesheet href=/assets/css/tooltip.css><link rel=stylesheet href=https://unpkg.com/bulmaswatch/united/bulmaswatch.min.css><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=/css/blog-post.css><link rel=stylesheet href=/css/code-highlighting/dark.css><link rel=stylesheet href=/css/custom.css><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],tags:'ams',processEscapes:true,processEnvironments:true},options:{skipHtmlTags:['script','noscript','style','textarea','pre']},svg:{fontCache:'global'}};window.addEventListener('load',(event)=>{document.querySelectorAll("mjx-container").forEach(function(x){x.parentElement.classList+='has-jax'})});</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>mermaid.initialize({startOnLoad:true});</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css integrity="sha512-9usAa10IRO0HhonpyAIVpjrylPvoDwiPUiKdWk5t3PyolY1cOd4DSE0Ga+ri4AuTroPR5aQvXU9xC6qOPnzFeg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/js/all.min.js integrity="sha512-yFjZbTYRCJodnuyGlsKamNE/LlEaEAxSUDe5+u61mV8zzqJVFOH7TnULE2/PP/l5vKWpUNnF4VGVkXh3MjgLsg==" crossorigin=anonymous referrerpolicy=no-referrer></script></head><body><header><nav class="navbar is-transparent"><div class=navbar-brand><a class=navbar-item href=/><img src=/images/logos/logo.png alt=NeuronStar height=28 style=margin-right:.5em> NeuronStar</a><div class="navbar-burger burger" style=color:#000 data-target=navMenu><span></span><span></span><span></span></div></div><div class=navbar-menu id=navMenu><div class=navbar-start><div class="navbar-item has-dropdown is-hoverable"><a href=/projects class=navbar-link>Groups</a><div class=navbar-dropdown><a href=https://neuronstar.github.io/cpe/ class=navbar-item>Conditional Probability Estimation</a>
<a href=https://neuronstar.github.io/snm/ class=navbar-item>Spiking Neuron Models Reading Club</a>
<a href=https://neuronstar.github.io/esl/ class=navbar-item>The Elements of Statistical Learning</a></div></div><div class="navbar-item has-dropdown is-hoverable"></div></div><span class=navbar-burger><span></span><span></span><span></span></span><div class=navbar-end><div class=navbar-item><a class=navbar-item href=/about/>About</a>
<a class=navbar-item href=https://dl.leima.is/>CPE Docs</a>
<a class=navbar-item href=https://github.com/orgs/neuronstar/discussions/categories/papers-please>Propose New Papers</a>
<a class=navbar-item href=https://github.com/orgs/neuronstar/discussions>Community</a>
<a class=navbar-item target=blank href=https://github.com/neuronstar><span class=icon><i class="fab fa-github"></i></span></a></div></div></div></nav><script>document.addEventListener('DOMContentLoaded',()=>{const $navbarBurgers=Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'),0);if($navbarBurgers.length>0){$navbarBurgers.forEach(el=>{el.addEventListener('click',()=>{const target=el.dataset.target;const $target=document.getElementById(target);console.log("target",target)
console.log("$target",$target)
el.classList.toggle("is-active");console.log("active el",el)
console.log("active $target",$target)});});}});</script></header><main><div class=container itemscope itemtype=http://schema.org/BlogPosting><meta itemprop=name content="21.Asynchronous Firing"><meta itemprop=description content="Asynchronous firing of homogeneous network"><meta itemprop=datePublished content="2016-10-14T00:00:00+00:00"><meta itemprop=dateModified content="2016-10-14T00:00:00+00:00"><meta itemprop=wordCount content="1211"><meta itemprop=keywords content><section class=section><div class=container><article class=post><header class=post-header><nav class="breadcrumb has-succeeds-separator is-small" aria-label=breadcrumbs><ul><li><a href=https://neuronstar.github.io/>NeuronStar</a></li><li><a href=https://neuronstar.github.io/snm/>Spiking Neuron Models Reading Club</a></li><li class=active><a href=https://neuronstar.github.io/snm/21.asynchronous-firing/>21.Asynchronous Firing</a></li></ul></nav><h1 class="post-title has-text-centered is-size-1" itemprop="name headline">21.Asynchronous Firing</h1><h2 class="title is-6 has-text-centered"><i class="fas fa-tags" style=margin-right:.5em></i></h2></header><div class=columns><div class="column is-8"><div class=is-divider data-content=SUMMARY></div><div class="notification is-light"><p>Asynchronous firing of homogeneous network</p></div><div class=is-divider data-content=ARTICLE></div><div class="content blog-post section" itemprop=articleBody><h2 id=review-of-concepts>Review of Concepts</h2><ol start=0><li><p>Population activity $A(t)$: fraction of neurons fired per unit time at time $t$.</p></li><li><p>Interval distribution $P_I(t-\hat t\vert t)$: given external input $I$, the</p></li><li><p>Mean firing rate $\nu$: reciprocal of mean firing interval $\langle T\rangle$</p><p>$$
\begin{equation}
\nu = \frac{1}{\langle T \rangle} = \int s P(s) ds,
\end{equation}
$$</p><p>where $s$ is the interval between firing.</p></li></ol><h2 id=asynchronous-firing>Asynchronous Firing</h2><p><strong>Asynchronous firing</strong> is a state when the population activity $A(t)=A_0$ is a constant of time. In this section we deal with homogeneous network and constant external input.</p><blockquote><p>Whether it is possible to have equilibrium if we apply variant external input is still up for discussion.</p></blockquote><p>Equilibrium means that we need only the parameter $s=t-\hat t$ to describe each neuron. Hence we simplify the probabilities</p><p>$$
\begin{align}
P_I(t-\hat t\vert \hat t) &= P_0(s), \<br>S_I(t-\hat t\vert \hat t) &= S_0(s).
\end{align}
$$</p><p>This corresponds to <strong>equilibrium state</strong> of the whole system. In statistical physics, we have the concept of <strong>equal priori probability</strong> <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. The question is, does it hold for neural networks?</p><p>The first question, though, is how to describe a microstate of a neural network. To simplify the idea, we discuss equilibrium systems. We could easily deny the idea of using spiking states, since it obviously gives much less information we should have.</p><p>My idea is to use the time lapsed after the spike $s = t-\hat t$. If we can know exactly the $s$ of each neuron for an equilibrium state or asynchronous firing, we can determine the firing of the system probabilistically or on average.</p><p>Here is an example. Suppose we have 4 neurons in a network, and the system reaches equilibrium.</p><p>| Neuron Number | 1 | 2 | 3 | 4 |
| $s^{(1)}$ | 0.1 | 0.7 | 0.4 | 0.2 |
| $s^{(2)}$ | 0.5 | 0.8 | 0.3 | 0.4 |</p><p>The indices ${}^{(i)}$'s are the encoding of ensembles. Do they have equal probability?</p><p>NO! This is why we have the interval distribution!</p><p>This either means we do not have equal priori probability principle or I didn&rsquo;t find the correct way to describe all the accessible states of the system.</p><p>However, another notion that bothers me is that in statistical physics, we have Avogadro number of particles so that the fluctuations $1/\sqrt{N}$ is small. What about neural networks? How do we justify the analogy of equilibrium state/ensemble?</p><h3 id=is-a_0-the-same-as-mean-firing-rate>Is $A_0$ the same as mean firing rate?</h3><p>Naively, we would expect that $A_0$ equals the mean firing rate since we have only one time scale for the whole system which is the mean firing interval and $A_0$ has dimension $1/[T]$. Here is a handwaving argument.</p><p>$$
\begin{align}
&\text{Total number of neurons} \cdot A_0 \cdot \Delta t \<br>\equiv & \text{Number of neurons firing during time interval $\Delta t$} \<br>\equiv & \text{Total number of neurons} \cdot \frac{\Delta t}{\text{Mean firing interval of each neuron} }
\end{align}
$$</p><p>The last step is an educated guess. We are pretty sure about this forumla because we can take the limit that $\Delta t=\text{Mean firing interval}$ and all neurons have constant firing interval.</p><p>To prove this conjecture, we need to investigate the equations for $A_0$. We consider the normalization equation</p><p>$$
\int_{-\infty}^t A_0 S_0(t-\hat t) d\hat t = 1.
$$</p><p>Change integration variable from $\hat t$ to $s$, which are related through $\hat t=t-s$,</p><p>$$
\int_{-\infty}^t A_0 S_0(t-\hat t) d\hat t = \int_0^{\infty}A_0 S_0(s)ds.
$$</p><p>We integrate by parts</p><p>$$
\begin{align}
&\int_0^{\infty}A_0 S_0(s)ds \<br>=& A_0 \int_0^\infty d(S_0 \cdot s) - A_0 \int_0^\infty s d S_0 \<br>=& A_0 \cdot s\cdot S_0(s)\vert_0^\infty - A_0 \int_0^\infty s \frac{dS_0}{ds} ds\<br>=& A_0 \int_0^\infty s P_0(s) ds
\end{align}
$$</p><p>In the last step, we used</p><p>$$
\begin{equation}
\frac{dS_0(s)}{ds} = - P_0(s).
\end{equation}
$$</p><p>The term $\int_0^\infty s P_0(s) ds$ is exactly the definition of mean interspike interval $\langle T\rangle$. So we have proved</p><p>$$
\begin{equation}
A_0 \langle T\rangle = 1.
\end{equation}
$$</p><p>Numerically, they show that the averaged fluctuations $\langle \lvert \bar A(t) - A_0 \rvert^2 \rangle$ decrease as the number of neurons increase. Fig. 6.9.</p><h3 id=gain-function-and-fixed-points>Gain function and fixed points</h3><p>Gain function: $1/\langle T \rangle$ as a function of input current.</p><p>$$
\begin{equation}
A_0 = g(I_0),
\end{equation}
$$</p><p>where</p><p>$$
I_0 = I^{\mathrm{ext}}_0 + I^{\mathrm{int}}_0.
$$</p><p>The subscript $0$ indicates that we are talking about stationary cases. If we apply SRM0 model,</p><p>$$
\begin{equation}
h(t) = J_0 A_0 \int_0^\infty \epsilon_0(s) ds + I^{\mathrm{ext}}_0 \int_0^\infty \kappa_0 (s)ds
\end{equation}
$$</p><p>becomes time independent.</p><p>Since $\int_0^\infty \epsilon_0(s) ds$ is time independent, we can redefine a new quantitity</p><p>$$
J_0^{(1)} \equiv J_0 \int_0^\infty \epsilon_0(s) ds.
$$</p><p>Meanwhile, our observation tells us that $\int_0^\infty \kappa_0 (s)ds$ is a effective resistance.</p><p>Thus we obtain</p><p>$$
h = J_0^{(1)} A_0 + I^{\mathrm{ext}}_0 R.
$$</p><p>To obtain the current, we devided the equation by $R$,</p><p>$$
I_0 = J_0^{(2)} A_0 + I^{\mathrm{ext}}_0,
$$</p><p>where</p><p>$$
J_0^{(2)} = J_0^{(1)} /R.
$$</p><p>For convinience we call just drop all these superscripts and name $J_0^{(2)}$ as $J_0$, i.e.,</p><p>$$
I_0 = J_0 A_0 + I^{\mathrm{ext}}_0.
$$</p><p>The <strong>gain function</strong> becomes</p><p>$$
A_0 = g(J_0 A_0 + I^{\mathrm{ext}}_0).
$$</p><p>This equation seems to be complicated. A graphical method is provided in the textbook. An easy way to understand this method is to rewrite the equation into two,</p><p>$$
\begin{align}
A_0 = & g(I_0) \<br>A_0 =& \frac{I_0 - I^{\mathrm{ext}}_0 }{J_0},
\end{align}
$$</p><p>which is equivalently</p><p>$$
\begin{equation}
\frac{I_0 - I^{\mathrm{ext}}_0 }{J_0} =g(I_0)
\label{eq-graphical-solution-illustration}
\end{equation}
$$</p><p>If we plot $A_0$ as a function of $I_0$, the solution to the system of equations should be where the LHS = RHS in Eq.(\ref{eq-graphical-solution-illustration}). More explicitly, we plot out LHS and RHS as a function of $I_0$ and the intersection is the solution.</p><h2 id=low-connectivity-networks>Low Connectivity Networks</h2><p>Same neurons but the connections are not full.</p><ol><li>Each neuron takes input from $C$ neurons.</li><li>Sparse connectivity: $C/N \gg 1$.</li><li>Sparse also means any two neurons i and j hardly take input from the same neurons.</li><li><strong>IF</strong> the presynaptic signals are stochastic, the neurons take stochastic inputs, thus described by diffusive noise.</li></ol><p>How can we be sure that the presynaptic signals are stochastic? This loophole is solved by proving that the system has such solutions.</p><p>Assuming two types of populations, excitatory neurons $N_E$ and inhibitory neurons $N_I$, each neuron has connectivity $C_E$ from $N_E$ and $C_I$ from $N_I$.</p><p>$$
\begin{equation}
h_0 = R I^{\mathrm{ext}} + \tau_m \sum_j \nu_j w_j
\end{equation}
$$</p><p>We have</p><p>$$
\begin{align}
w_j = & w_E C_E + w_I C_I \<br>=& w_E C_E (1 - g\gamma),
\end{align}
$$</p><p>where</p><p>$$
\begin{align}
g = & - \frac{w_I}{w_E} \<br>\gamma = & \frac{C_I}{C_E}.
\end{align}
$$</p><p>Similarly,</p><p>$$
\begin{align}
\sigma^2 = & \tau_m \sum_j v_j w_j^2 \<br>=& \tau_m v (w_E^2 C_E + w_I^2 C_I) \<br>=& \tau_m v w_E^2 C_E^2 (1+g^2\gamma).
\end{align}
$$</p><p>Then we can calculate the population activity: Eq. 6.110, which is a function that depends on $h_0$ and $\sigma$. Hence we can find population activity given all the parameters:</p><ol><li>Threshold $\theta$</li><li>Life time $\tau_m$</li><li>$w_E$</li><li>$C_E$</li><li>$g$</li><li>$\gamma$</li><li>External $I^{\mathrm{ext}}$</li><li>Resistance $R$</li></ol><p>The book has two examples of verifying that in some conditions such randomly connected sparse network is equivalent to noise</p><h2 id=references-and-notes>References and Notes</h2><ol><li><a href=http://wpage.unina.it/mdaquino/PhD_thesis/main/node9.html>Weiss Theory of Ferromagnetism</a></li></ol><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>For some explaination of this concept, please read <a href=http://farside.ph.utexas.edu/teaching/sm1/lectures/node25.html>The principle of equal a priori probabilities</a> and <a href=http://farside.ph.utexas.edu/teaching/sm1/lectures/node29.html>Probability calculations</a>. <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></div><p><div class="has-text-right is-size-7"><span class=icon><i class="fas fa-pencil-alt"></i></span>Planted: <time datetime=2016-10-14T00:00:00+00:00>2016-10-14</time>
by <span itemprop=author>OctoMiao</span>;</div></p><div class=is-divider></div><nav class="pagination is-centered" role=navigation aria-label=pagination><a href="https://neuronstar.github.io/snm/20.basics-of-renewal-theory/?ref=footer" class=pagination-previous>« 20.Basics of Renewal Theory</a>
<a class=pagination-next href="https://neuronstar.github.io/snm/22.interacting-populations-and-continuum-models/?ref=footer">22.interacting populations and continuum models »</a></nav></div><div class="column is-4"><style>#TableOfContents>ul{list-style-type:lower-greek;padding-left:0}#TableOfContents>ul>li ul{list-style-type:none;padding-left:1em}</style><div class=is-divider data-content=ToC></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><details><summary><i class="fa-solid fa-list-ol"></i>Table of Contents</summary><div><div><nav id=TableOfContents><ul><li><a href=#review-of-concepts>Review of Concepts</a></li><li><a href=#asynchronous-firing>Asynchronous Firing</a><ul><li><a href=#is-a_0-the-same-as-mean-firing-rate>Is $A_0$ the same as mean firing rate?</a></li><li><a href=#gain-function-and-fixed-points>Gain function and fixed points</a></li></ul></li><li><a href=#low-connectivity-networks>Low Connectivity Networks</a></li><li><a href=#references-and-notes>References and Notes</a></li></ul></nav></div></div></details></div></div></article></div><script>const el=document.querySelector('details summary')
el.onclick=()=>{(function(l,o,a,d,e,r){e=o.createElement(a),r=o.getElementsByTagName(a)[0];e.async=1;e.src=d;r.parentNode.insertBefore(e,r)})(window,document,'script','/js/smoothscroll.js');el.onclick=null}
document.querySelectorAll('#TableOfContents a').forEach(link=>{link.addEventListener('click',()=>{document.querySelector(link.href.slice(link.href.indexOf('#'))).scrollIntoView({behavior:'smooth'})})})</script><div class=is-divider data-content=REFERENCES></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>References:</strong><br><ol><li class=has-text-weight-bold><a href style=text-decoration:none>Spiking Neuron Models, Section 6.4</a></li></ol></p></div></div></article></div><div class=is-divider data-content=CONNECTUME></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>Current Ref:</strong><br><ul><li style=list-style:none><span class="tag is-primary is-light has-text-weight-bold">snm/21.asynchronous-firing.md</span></li></ul></p></div></div></article></div><div id=comments class=is-divider data-content=COMMENTS></div><script src=https://giscus.app/client.js data-repo=neuronstar/neuronstar.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkzMjY1MDkyMg==" data-category=Comments data-category-id=DIC_kwDOAfI2qs4B-wVl data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=1 data-theme=light crossorigin=anonymous async></script></div></div></article></div></section></div><div class=navtools><a class="button is-primary is-light is-outlined" alt="Edit this page" href=https://github.com/neuronstar/neuronstar.github.io/edit/master/content/snm/21.asynchronous-firing.md target=blank style=position:fixed;bottom:20px;right:10px;border-radius:9999px;width:35px;height:35px><i class="fas fa-pencil-alt"></i></a><a class="button is-primary is-light is-outlined" href=#comments alt=Comments style=position:fixed;bottom:60px;right:10px;border-radius:9999px;width:35px;height:35px><i class="far fa-comments"></i></a><a class="button is-primary is-light is-outlined" href=#connectome alt=Connectome style=position:fixed;bottom:100px;right:10px;border-radius:9999px;width:35px;height:35px><i class="fa-solid fa-brain"></i></a></div></main><footer><footer class=footer><div class=container><div class="content has-text-centered"><p>Created and maintained by <a href=https://neuronstar.github.io/>NeuronStar</a>.
Acknowledgement: <a href=https://gohugo.io/>Hugo</a>,
<a href=https://themes.gohugo.io/bulma/>Bulma</a>, <a href=https://kausalflow.com>KausalFlow</a>.
<strong>love</strong>.<br><a class=tag href=/index.xml>Feed</a>
<a class=tag href=/data.json>JSON Data</a></p></div></div></footer></footer><script async type=text/javascript src=/js/bulma.js></script><script type=application/json class=js-hypothesis-config>{"openSidebar":false,"theme":"clean","enableExperimentalNewNoteButton":true,"showHighlights":true}</script><script async src=https://hypothes.is/embed.js></script></body></html>