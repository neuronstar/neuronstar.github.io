<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:project="http://neuronstar.github.io/projects"><channel><title>Conditional Probability Estimation on NeuronStar</title><link>https://neuronstar.github.io/cpe/</link><description>Recent content in Conditional Probability Estimation on NeuronStar</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Sun, 16 Oct 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://neuronstar.github.io/cpe/index.xml" rel="self" type="application/rss+xml"/><item><title>Forecasting with Trees</title><link>https://neuronstar.github.io/cpe/44.forecasting-with-trees/</link><pubDate>Sun, 16 Oct 2022 00:00:00 +0000</pubDate><project:when_start>2022-10-29T15:00:00</project:when_start><project:when_end>2022-10-29T16:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/44.forecasting-with-trees/</guid><description>(<time>2022-10-29T15:00:00</time> -<time>2022-10-29T16:30:00</time>)&lt;br/> Topic: Forecasting with Trees
References:
https://www.sciencedirect.com/science/article/pii/S0169207021001679 Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Gradient Boosted Decision Trees (II)</title><link>https://neuronstar.github.io/cpe/43.gbdt-2/</link><pubDate>Mon, 22 Aug 2022 00:00:00 +0000</pubDate><project:when_start>2022-10-15T15:00:00</project:when_start><project:when_end>2022-10-15T16:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/43.gbdt-2/</guid><description>(<time>2022-10-15T15:00:00</time> -<time>2022-10-15T16:30:00</time>)&lt;br/> Topic: XGBoost, LightGBM and Trees (II)
References:
https://lightgbm.readthedocs.io/en/v3.3.2/ https://papers.nips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Gradient Boosted Decision Trees (I)</title><link>https://neuronstar.github.io/cpe/42.gbdt-1/</link><pubDate>Mon, 22 Aug 2022 00:00:00 +0000</pubDate><project:when_start>2022-10-01T15:00:00</project:when_start><project:when_end>2022-10-01T16:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/42.gbdt-1/</guid><description>(<time>2022-10-01T15:00:00</time> -<time>2022-10-01T16:30:00</time>)&lt;br/> Topic: XGBoost, LightGBM and Trees (I)
References: https://xgboost.readthedocs.io/en/stable/tutorials/model.html
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Neural ODE</title><link>https://neuronstar.github.io/cpe/41.neural-ode/</link><pubDate>Mon, 22 Aug 2022 00:00:00 +0000</pubDate><project:when_start>2022-09-03T15:00:00</project:when_start><project:when_end>2022-09-03T16:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/41.neural-ode/</guid><description>(<time>2022-09-03T15:00:00</time> -<time>2022-09-03T16:30:00</time>)&lt;br/> Topic:
Chen RTQ, Rubanova Y, Bettencourt J, Duvenaud D. Neural Ordinary Differential Equations. arXiv [cs.LG]. 2018. Available: http://arxiv.org/abs/1806.07366
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>M Competition</title><link>https://neuronstar.github.io/cpe/40.m-competition/</link><pubDate>Sun, 07 Aug 2022 00:00:00 +0000</pubDate><project:when_start>2022-08-20T15:00:00</project:when_start><project:when_end>2022-08-20T16:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/40.m-competition/</guid><description>(<time>2022-08-20T15:00:00</time> -<time>2022-08-20T16:30:00</time>)&lt;br/> We will discuss the M competition.
@小紫花:
M5: 2020 年的一个比赛，预测沃尔玛在米国 3 个州、 10 个店、3000 多个产品的销售，要求预测 28 天。两个比赛：预测一个中值，或者预测一个分布（9 个数）。今年有 M6 官网，指引 PDF https://mofc.unic.ac.cy/m5-competition/ 中值 https://www.kaggle.com/competitions/m5-forecasting-accuracy/ 分布 https://www.kaggle.com/competitions/m5-forecasting-uncertainty 比赛背景、组织、运营总结 https://www.sciencedirect.com/science/article/pii/S0169207021001187 中值预测总结 https://www.sciencedirect.com/science/article/pii/S0169207021001874 分布预测总结（我比较感兴趣） https://www.sciencedirect.com/science/article/pii/S0169207021001722 一篇评论文章 https://www.sciencedirect.com/science/article/abs/pii/S016920702100128X 对讨论的回复 https://www.sciencedirect.com/science/article/abs/pii/S0169207022000644
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Data Augmentation for Time Series</title><link>https://neuronstar.github.io/cpe/39.data-augmentation-ts/</link><pubDate>Mon, 01 Aug 2022 00:00:00 +0000</pubDate><project:when_start>2022-08-06T15:00:00</project:when_start><project:when_end>2022-08-06T16:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/39.data-augmentation-ts/</guid><description>(<time>2022-08-06T15:00:00</time> -<time>2022-08-06T16:30:00</time>)&lt;br/> Wen Q, Sun L, Yang F, Song X, Gao J, Wang X, et al. Time Series Data Augmentation for Deep Learning: A Survey. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2002.12478
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Temporal Fusion Transformer</title><link>https://neuronstar.github.io/cpe/38.tft/</link><pubDate>Sat, 09 Jul 2022 00:00:00 +0000</pubDate><project:when_start>2022-07-23T15:00:00</project:when_start><project:when_end>2022-07-23T16:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/38.tft/</guid><description>(<time>2022-07-23T15:00:00</time> -<time>2022-07-23T16:30:00</time>)&lt;br/> Lim B, Arik SO, Loeff N, Pfister T. Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting. In: arXiv.org [Internet]. 19 Dec 2019 [cited 9 Jul 2022]. Available: https://arxiv.org/abs/1912.09363
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>DeepAR</title><link>https://neuronstar.github.io/cpe/37.deepar/</link><pubDate>Fri, 10 Jun 2022 00:00:00 +0000</pubDate><project:when_start>2022-06-25T15:00:00</project:when_start><project:when_end>2022-06-25T16:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/37.deepar/</guid><description>(<time>2022-06-25T15:00:00</time> -<time>2022-06-25T16:30:00</time>)&lt;br/> Topic: DeepAR.
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Evaluating time series forecasting models</title><link>https://neuronstar.github.io/cpe/36.evaluating-forecasting-models/</link><pubDate>Fri, 10 Jun 2022 00:00:00 +0000</pubDate><project:when_start>2022-06-11T15:00:00</project:when_start><project:when_end>2022-06-11T16:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/36.evaluating-forecasting-models/</guid><description>(<time>2022-06-11T15:00:00</time> -<time>2022-06-11T16:30:00</time>)&lt;br/> Our topic for this session is
Cerqueira V, Torgo L, Mozetic I. Evaluating time series forecasting models: An empirical study on performance estimation methods. arXiv [cs.LG]. 2019. Available: http://arxiv.org/abs/1905.11744
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Inferring causal impact using Bayesian structural time-series models</title><link>https://neuronstar.github.io/cpe/tbd.causal-impact-bayesian-structural-ts-models/</link><pubDate>Sat, 21 May 2022 00:00:00 +0000</pubDate><project:when_start>2022-06-11T15:00:00</project:when_start><project:when_end>2022-06-11T16:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/tbd.causal-impact-bayesian-structural-ts-models/</guid><description>(<time>2022-06-11T15:00:00</time> -<time>2022-06-11T16:30:00</time>)&lt;br/> Our topic for this session is Inferring causal impact using Bayesian structural time-series models (arXiv:1506.00356).
Abstract
Abstract of Inferring causal impact using Bayesian structural time-series models (arXiv:1506.00356):
An important problem in econometrics and marketing is to infer the causal impact that a designed market intervention has exerted on an outcome metric over time. This paper proposes to infer causal impact on the basis of a diffusion-regression state-space model that predicts the counterfactual market response in a synthetic control that would have occurred had no intervention taken place.</description></item><item><title>Causal Inference</title><link>https://neuronstar.github.io/cpe/35.causal-inference/</link><pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate><project:when_start>2022-05-21T15:00:00</project:when_start><project:when_end>2022-05-21T16:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/35.causal-inference/</guid><description>(<time>2022-05-21T15:00:00</time> -<time>2022-05-21T16:30:00</time>)&lt;br/> Alexa will lead a discussion on causal inference.
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Review of Time Series Forecasting</title><link>https://neuronstar.github.io/cpe/33.review-of-timeseries-2/</link><pubDate>Tue, 12 Apr 2022 00:00:00 +0000</pubDate><project:when_start>2022-04-23T15:00:00</project:when_start><project:when_end>2022-04-23T16:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/33.review-of-timeseries-2/</guid><description>(<time>2022-04-23T15:00:00</time> -<time>2022-04-23T16:30:00</time>)&lt;br/> Lim B, Zohren S. Time Series Forecasting With Deep Learning: A Survey. arXiv [stat.ML]. 2020. Available: http://arxiv.org/abs/2004.13408
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Counterfactual Explanation in Multivariate Time Series</title><link>https://neuronstar.github.io/cpe/34.counterfactual-prediction-multivariate-time-series/</link><pubDate>Tue, 12 Apr 2022 00:00:00 +0000</pubDate><project:when_start>2022-05-07T15:00:00</project:when_start><project:when_end>2022-05-07T16:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/34.counterfactual-prediction-multivariate-time-series/</guid><description>(<time>2022-05-07T15:00:00</time> -<time>2022-05-07T16:30:00</time>)&lt;br/> Ates E, Aksar B, Leung VJ, Coskun AK. Counterfactual Explanations for Machine Learning on Multivariate Time Series Data. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2008.10781
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Conformal Time Series Forecasting</title><link>https://neuronstar.github.io/cpe/32.review-of-timeseries/</link><pubDate>Thu, 10 Mar 2022 00:00:00 +0000</pubDate><project:when_start>2022-04-09T15:00:00</project:when_start><project:when_end>2022-04-09T16:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/32.review-of-timeseries/</guid><description>(<time>2022-04-09T15:00:00</time> -<time>2022-04-09T16:30:00</time>)&lt;br/> We start our new journey on time series by sharing and discussing two review papers:
Lim B, Zohren S. Time Series Forecasting With Deep Learning: A Survey. arXiv [stat.ML]. 2020. Available: http://arxiv.org/abs/2004.13408 Gneiting T, Katzfuss M. Probabilistic Forecasting. Annu Rev Stat Appl. 2014;1: 125–151. doi:10.1146/annurev-statistics-062713-085831 (pdf) Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Uncertainty in Deep Learning</title><link>https://neuronstar.github.io/cpe/31.uncertaintyt-in-deep-learning/</link><pubDate>Sat, 26 Feb 2022 00:00:00 +0000</pubDate><project:when_start>2022-03-26T14:00:00</project:when_start><project:when_end>2022-03-26T15:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/31.uncertaintyt-in-deep-learning/</guid><description>(<time>2022-03-26T14:00:00</time> -<time>2022-03-26T15:30:00</time>)&lt;br/> Topic: uncertainty in deep learning
References:
Gawlikowski, J. et al. A Survey of Uncertainty in Deep Neural Networks. Arxiv (2021). Jospin, L. V., Buntine, W., Boussaid, F., Laga, H. &amp;amp; Bennamoun, M. Hands-on Bayesian Neural Networks &amp;ndash; a Tutorial for Deep Learning Users. Arxiv (2020). Gal, Yarin. &amp;ldquo;Uncertainty in deep learning.&amp;rdquo; (2016): 3. Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.</description></item><item><title>Hamilton WL. Graph Representation Learning. Chapter 8 (2)</title><link>https://neuronstar.github.io/cpe/30.hamilton-traditional-graph-generation-approaches-2/</link><pubDate>Fri, 18 Feb 2022 00:00:00 +0000</pubDate><project:when_start>2022-02-26T14:00:00</project:when_start><project:when_end>2022-02-26T15:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/30.hamilton-traditional-graph-generation-approaches-2/</guid><description>(<time>2022-02-26T14:00:00</time> -<time>2022-02-26T15:30:00</time>)&lt;br/> We will wrap up Chapter 8 of Hamilton WL. Graph Representation Learning: Graph Generation.
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Hamilton WL. Graph Representation Learning. Chapter 8</title><link>https://neuronstar.github.io/cpe/29.hamilton-traditional-graph-generation-approaches/</link><pubDate>Sat, 05 Feb 2022 00:00:00 +0000</pubDate><project:when_start>2022-02-12T14:00:00</project:when_start><project:when_end>2022-02-12T15:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/29.hamilton-traditional-graph-generation-approaches/</guid><description>(<time>2022-02-12T14:00:00</time> -<time>2022-02-12T15:30:00</time>)&lt;br/> Our topic for this session is Chapter 8 of Hamilton WL. Graph Representation Learning: Traditional GraphGeneration Approaches.
Use the following timezone tool or click on the &amp;ldquo;Add to Calendar&amp;rdquo; button on the sidebar.
Click here for an interactive widget.</description></item><item><title>Multivariate Time-series Forecasting Using GNN</title><link>https://neuronstar.github.io/cpe/28.gnn-time-series-forecasting/</link><pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate><project:when_start>2022-01-15T14:00:00</project:when_start><project:when_end>2022-01-15T15:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/28.gnn-time-series-forecasting/</guid><description>(<time>2022-01-15T14:00:00</time> -<time>2022-01-15T15:30:00</time>)&lt;br/> Our topic for this session is Spectral Temporal Graph Neural Network for multivariate time-series forecasting (arXiv:2103.07719).
Abstract
Abstract of Spectral Temporal Graph Neural Network for multivariate time-series forecasting (arXiv:2103.07719):
Multivariate time-series forecasting plays a crucial rolein many real-world ap-plications. It is a challenging problem as one needs to consider both intra-seriestemporal correlations and inter-series correlations simultaneously. Recently, there have been multiple works trying to capture both correlations, but most, if not allof them only capture temporal correlations in the time domain and resort to pre-defined priors as inter-series relationships.</description></item><item><title>Graph Convolutional Matrix Completion</title><link>https://neuronstar.github.io/cpe/27.graph-convolutional-matrix-completion/</link><pubDate>Sat, 11 Dec 2021 00:00:00 +0000</pubDate><project:when_start>2021-12-18T14:00:00</project:when_start><project:when_end>2021-12-18T15:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/27.graph-convolutional-matrix-completion/</guid><description>(<time>2021-12-18T14:00:00</time> -<time>2021-12-18T15:30:00</time>)&lt;br/> Our topic for this session is Graph Convolutional Matrix Completion (arXiv:1706.02263).
Abstract
Abstract of Graph Convolutional Matrix Completion (arXiv:1706.02263):
We consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph.</description></item><item><title>Graph Neural Networks: Theoretical Motivations (Part 2)</title><link>https://neuronstar.github.io/cpe/26.gnn-3/</link><pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate><project:when_start>2021-11-04T14:00:00</project:when_start><project:when_end>2021-11-04T15:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/26.gnn-3/</guid><description>(<time>2021-11-04T14:00:00</time> -<time>2021-11-04T15:30:00</time>)&lt;br/> We discussed the first section of Chapter 7. In this event, we will continue discussing chapter 7 of Hamilton1.
In this chapter, we will visit some of the theoretical underpinnings of graph neu- ral networks (GNNs). One of the most intriguing aspects of GNNs is that they were independently developed from distinct theoretical motivations.
Click here for an interactive widget.
Hamilton2020 Hamilton WL.</description></item><item><title>Graph Neural Networks: Theoretical Motivations</title><link>https://neuronstar.github.io/cpe/25.gnn-2/</link><pubDate>Fri, 12 Nov 2021 00:00:00 +0000</pubDate><project:when_start>2021-11-20T14:00:00</project:when_start><project:when_end>2021-11-20T15:30:00</project:when_end><guid>https://neuronstar.github.io/cpe/25.gnn-2/</guid><description>(<time>2021-11-20T14:00:00</time> -<time>2021-11-20T15:30:00</time>)&lt;br/> We have changed the time!</description></item><item><title>Graph Neural Networks: PyTorch</title><link>https://neuronstar.github.io/cpe/24.gnn-pytorch/</link><pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate><project:when_start>2021-11-06T13:30:00</project:when_start><project:when_end>2021-11-06T15:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/24.gnn-pytorch/</guid><description>(<time>2021-11-06T13:30:00</time> -<time>2021-11-06T15:00:00</time>)&lt;br/> We will go through the GNN tutorial by Phillip Lippe.</description></item><item><title>Graph Neural Networks</title><link>https://neuronstar.github.io/cpe/23.gnn/</link><pubDate>Tue, 19 Oct 2021 00:00:00 +0000</pubDate><project:when_start>2021-10-23T14:30:00</project:when_start><project:when_end>2021-10-23T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/23.gnn/</guid><description>(<time>2021-10-23T14:30:00</time> -<time>2021-10-23T16:00:00</time>)&lt;br/> Chapter 5 of Hamilton1.
Hamilton2020 Hamilton WL. Graph representation learning. Synth lect artif intell mach learn. 2020;14: 1–159. doi:10.2200/s01045ed1v01y202009aim046 &amp;#x21a9;&amp;#xfe0e;</description></item><item><title>Graph Neural Networks: Basics (2)</title><link>https://neuronstar.github.io/cpe/22.gnn-basics-2/</link><pubDate>Sun, 03 Oct 2021 00:00:00 +0000</pubDate><project:when_start>2021-10-09T14:30:00</project:when_start><project:when_end>2021-10-09T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/22.gnn-basics-2/</guid><description>(<time>2021-10-09T14:30:00</time> -<time>2021-10-09T16:00:00</time>)&lt;br/> We will continue the discussion on Graph Neural Networks.
Problems of using Graphs Graph Neural Networks Textbook: Hamilton1
Hamilton2020 Hamilton WL. Graph representation learning. Synth lect artif intell mach learn. 2020;14: 1–159. doi:10.2200/s01045ed1v01y202009aim046 &amp;#x21a9;&amp;#xfe0e;</description></item><item><title>Graph Neural Networks: Basics</title><link>https://neuronstar.github.io/cpe/21.gnn-basics/</link><pubDate>Sat, 11 Sep 2021 00:00:00 +0000</pubDate><project:when_start>2021-09-25T14:30:00</project:when_start><project:when_end>2021-09-25T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/21.gnn-basics/</guid><description>(<time>2021-09-25T14:30:00</time> -<time>2021-09-25T16:00:00</time>)&lt;br/> This will be the beginning of a new topic: Graph Neural Networks. In this new series, we will use the textbook by Hamilton1. For the first episode, we will discuss some basics about graphs to make sure we are all on the same page.
@Steven will lead the discussion.
Hamilton2020 Hamilton WL. Graph representation learning. Synth lect artif intell mach learn. 2020;14: 1–159. doi:10.2200/s01045ed1v01y202009aim046 &amp;#x21a9;&amp;#xfe0e;</description></item><item><title>Self-supervised Learning: Theories (Part 2)</title><link>https://neuronstar.github.io/cpe/20.self-supervised-learning-theories-2/</link><pubDate>Thu, 26 Aug 2021 00:00:00 +0000</pubDate><project:when_start>2021-09-11T14:30:00</project:when_start><project:when_end>2021-09-11T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/20.self-supervised-learning-theories-2/</guid><description>(<time>2021-09-11T14:30:00</time> -<time>2021-09-11T16:00:00</time>)&lt;br/> We will dive deep into Section 6 of the paper arXiv:2006.08218. Here are a few topics to be explored.
InfoGAN objective; Positive and negative samples in loss function (InfoNCE); Uniformity in constrastive loss; JS-divergence.</description></item><item><title>Self-supervised Learning: Theories (Part 1)</title><link>https://neuronstar.github.io/cpe/19.self-supervised-learning-theories-1/</link><pubDate>Thu, 26 Aug 2021 00:00:00 +0000</pubDate><project:when_start>2021-08-28T14:30:00</project:when_start><project:when_end>2021-08-28T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/19.self-supervised-learning-theories-1/</guid><description>(<time>2021-08-28T14:30:00</time> -<time>2021-08-28T16:00:00</time>)&lt;br/> We will discuss Section 6 of the paper arXiv:2006.08218.</description></item><item><title>Self-supervised Learning: GAN</title><link>https://neuronstar.github.io/cpe/18.self-supervised-learning-gan/</link><pubDate>Sun, 01 Aug 2021 00:00:00 +0000</pubDate><project:when_start>2021-08-14T14:30:00</project:when_start><project:when_end>2021-08-14T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/18.self-supervised-learning-gan/</guid><description>(<time>2021-08-14T14:30:00</time> -<time>2021-08-14T16:00:00</time>)&lt;br/> We will discuss the reset of the paper arXiv:2006.08218.</description></item><item><title>Self-supervised Learning: Generative or Contrastive</title><link>https://neuronstar.github.io/cpe/17.self-supervised-learning/</link><pubDate>Sat, 03 Jul 2021 00:00:00 +0000</pubDate><project:when_start>2021-07-31T14:30:00</project:when_start><project:when_end>2021-07-31T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/17.self-supervised-learning/</guid><description>(<time>2021-07-31T14:30:00</time> -<time>2021-07-31T16:00:00</time>)&lt;br/> Liu X, Zhang F, Hou Z, Wang Z, Mian L, Zhang J, et al. Self-supervised Learning: Generative or Contrastive. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2006.08218
We have discussed many topics of generative models. This paper serves as a summary of the current season of the discussions.</description></item><item><title>LTD/LTP</title><link>https://neuronstar.github.io/cpe/16.ltd-ltp/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><project:when_start>2021-07-17T14:30:00</project:when_start><project:when_end>2021-07-17T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/16.ltd-ltp/</guid><description>(<time>2021-07-17T14:30:00</time> -<time>2021-07-17T16:00:00</time>)&lt;br/> In this meetup, we will discuss some key ideas related to biological neural network: LTP and LTD.</description></item><item><title>Predictive Coding Approximates Backprop along Arbitrary Computation Graphs</title><link>https://neuronstar.github.io/cpe/15.predictive-coding/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><project:when_start>2021-07-03T14:30:00</project:when_start><project:when_end>2021-07-03T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/15.predictive-coding/</guid><description>(<time>2021-07-03T14:30:00</time> -<time>2021-07-03T16:00:00</time>)&lt;br/> In this meetup, we will discuss this paper: https://arxiv.org/abs/2006.04182
Why? Feedforward-backprop usually has a loss function that involves all the parameters. Backprop means we need this huge global loss $\mathcal L({w_{ij}})$. However, it is hard to imaging such global loss calculations in our brain. One of the alternatives is predictive coding, which only utilizes local connection information.
In this paper (2006.04182), the author proves the equivalence of backprop and predictive coding on arbitary graph.</description></item><item><title>Energy-based Models 5</title><link>https://neuronstar.github.io/cpe/14.energy-based-learning-5/</link><pubDate>Wed, 02 Jun 2021 00:00:00 +0000</pubDate><project:when_start>2021-06-19T14:30:00</project:when_start><project:when_end>2021-06-19T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/14.energy-based-learning-5/</guid><description>(<time>2021-06-19T14:30:00</time> -<time>2021-06-19T16:00:00</time>)&lt;br/> In this meetup, we will discuss Restricted Boltzmann Machine (RBM). We will cover the reason for introducing RBM and the training. At the end of the discussion, we will also cover some topics of Deep Boltzmann Machines.</description></item><item><title>Energy-based Models 4</title><link>https://neuronstar.github.io/cpe/13.energy-based-learning-4/</link><pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate><project:when_start>2021-05-28T14:30:00</project:when_start><project:when_end>2021-05-28T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/13.energy-based-learning-4/</guid><description>(<time>2021-05-28T14:30:00</time> -<time>2021-05-28T16:00:00</time>)&lt;br/> In this discussion, we will discuss the Pytorch Deep Learning Lectures by LeCun.</description></item><item><title>Energy-based Models 3</title><link>https://neuronstar.github.io/cpe/12.energy-based-learning-3/</link><pubDate>Sat, 24 Apr 2021 00:00:00 +0000</pubDate><project:when_start>2021-05-15T14:30:00</project:when_start><project:when_end>2021-05-15T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/12.energy-based-learning-3/</guid><description>(<time>2021-05-15T14:30:00</time> -<time>2021-05-15T16:00:00</time>)&lt;br/> In the past two meetups, we have been discussing EBM from a computer scientist&amp;rsquo;s perspective.
In this discussion, we will discuss chapter XV of Mehta P, Bukov M, Wang C-HH, Day AGRR, Richardson C, Fisher CK, et al. A high-bias, low-variance introduction to Machine Learning for physicists. Phys Rep. 2018;810: 122. doi:10.1016/j.physrep.2019.03.001</description></item><item><title>Energy-based Models 2</title><link>https://neuronstar.github.io/cpe/11.energy-based-learning-2/</link><pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate><project:when_start>2021-04-24T14:30:00</project:when_start><project:when_end>2021-04-24T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/11.energy-based-learning-2/</guid><description>(<time>2021-04-24T14:30:00</time> -<time>2021-04-24T16:00:00</time>)&lt;br/> We will discuss energy-based learning in this session.
References:
Lecture notes: https://atcold.github.io/pytorch-Deep-Learning/[cid:90ae645c-415b-4c9f-8ea6-c78839a8e8d4] https://atcold.github.io/pytorch-Deep-Learning/en/week07/07-1/ https://atcold.github.io/pytorch-Deep-Learning/en/week07/07-2/ https://drive.google.com/file/d/1z8Dz1YtkOEJpU-gh5RIjORs3GGqkYJQa/view : if you can not access Google Drive, this file (007-ebm-01) has been attached to this calendar event too. Supplementary:
https://arxiv.org/pdf/1803.08823.pdf</description></item><item><title>Energy-based Models</title><link>https://neuronstar.github.io/cpe/10.energy-based-learning/</link><pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate><project:when_start>2021-04-10T13:30:00</project:when_start><project:when_end>2021-04-10T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/10.energy-based-learning/</guid><description>(<time>2021-04-10T13:30:00</time> -<time>2021-04-10T16:00:00</time>)&lt;br/> We will discuss energy-based learning in this session.
References:
Lecture notes: https://atcold.github.io/pytorch-Deep-Learning/[cid:90ae645c-415b-4c9f-8ea6-c78839a8e8d4] https://atcold.github.io/pytorch-Deep-Learning/en/week07/07-1/ https://atcold.github.io/pytorch-Deep-Learning/en/week07/07-2/ https://drive.google.com/file/d/1z8Dz1YtkOEJpU-gh5RIjORs3GGqkYJQa/view : if you can not access Google Drive, this file (007-ebm-01) has been attached to this calendar event too. Supplementary:
https://arxiv.org/pdf/1803.08823.pdf</description></item><item><title>Summary of Generative Models</title><link>https://neuronstar.github.io/cpe/09.summary-of-generative-models/</link><pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate><project:when_start>2021-03-27T13:30:00</project:when_start><project:when_end>2021-03-27T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/09.summary-of-generative-models/</guid><description>(<time>2021-03-27T13:30:00</time> -<time>2021-03-27T16:00:00</time>)&lt;br/></description></item><item><title>MAF: how is MADE being used</title><link>https://neuronstar.github.io/cpe/08.maf/</link><pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate><project:when_start>2021-03-13T13:30:00</project:when_start><project:when_end>2021-03-13T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/08.maf/</guid><description>(<time>2021-03-13T13:30:00</time> -<time>2021-03-13T16:00:00</time>)&lt;br/> We discussed MAF (arXiv:1705.07057v4) last time: The paper did not explain how exactly is MADE being used to update the shift and logscale.
We will use the tensorflow implementation of MAF to probe the above question. Here is the link to the relevant documentation: https://www.tensorflow.org/probability/api_docs/python/tfp/bijectors/MaskedAutoregressiveFlow
Topics Refer to references.
Notes 1310.8499_notes.pdf</description></item><item><title>MADE: Masked Autoencoder for Distribution Estimation</title><link>https://neuronstar.github.io/cpe/07.made/</link><pubDate>Sat, 27 Feb 2021 00:00:00 +0000</pubDate><project:when_start>2021-02-27T13:30:00</project:when_start><project:when_end>2021-02-27T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/07.made/</guid><description>(<time>2021-02-27T13:30:00</time> -<time>2021-02-27T16:00:00</time>)&lt;br/> Topics Refer to references.
Notes 1310.8499_notes.pdf</description></item><item><title>Deep AutoRegressive Networks</title><link>https://neuronstar.github.io/cpe/06.deep-autoregressive-networks/</link><pubDate>Sat, 13 Feb 2021 00:00:00 +0000</pubDate><project:when_start>2021-02-13T13:30:00</project:when_start><project:when_end>2021-02-13T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/06.deep-autoregressive-networks/</guid><description>(<time>2021-02-13T13:30:00</time> -<time>2021-02-13T16:00:00</time>)&lt;br/> Topics Refer to references.
Notes 1310.8499_notes.pdf</description></item><item><title>Review of Normalizing Flow</title><link>https://neuronstar.github.io/cpe/05.normalizing-flow-review/</link><pubDate>Sat, 30 Jan 2021 00:00:00 +0000</pubDate><project:when_start>2021-01-30T13:30:00</project:when_start><project:when_end>2021-01-30T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/05.normalizing-flow-review/</guid><description>(<time>2021-01-30T13:30:00</time> -<time>2021-01-30T16:00:00</time>)&lt;br/> Topics Normalizing flow Applications of normalizing flow Methods of normalizing flow Problems of normalizing flow</description></item><item><title>Variantional Inference Normalizing Flow</title><link>https://neuronstar.github.io/cpe/04.variational-inference-normalizing-flow/</link><pubDate>Sat, 16 Jan 2021 00:00:00 +0000</pubDate><project:when_start>2021-01-16T14:30:00</project:when_start><project:when_end>2021-01-16T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/04.variational-inference-normalizing-flow/</guid><description>(<time>2021-01-16T14:30:00</time> -<time>2021-01-16T16:00:00</time>)&lt;br/> Topics Variational Inference Normalizing Flow Variational Inference with Normalizing Flows</description></item><item><title>EM Methods</title><link>https://neuronstar.github.io/cpe/03.em-methods/</link><pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate><project:when_start>2021-01-02T14:30:00</project:when_start><project:when_end>2021-01-02T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/03.em-methods/</guid><description>(<time>2021-01-02T14:30:00</time> -<time>2021-01-02T16:00:00</time>)&lt;br/> Topics EM for Gaussian mixtures General EM algorithm Why does it work? Decomposition of log-likelihood into KL divergence and Relation between EM and Gibbs sampling</description></item><item><title>References for Probability Estimation Club</title><link>https://neuronstar.github.io/cpe/00.references/</link><pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate><guid>https://neuronstar.github.io/cpe/00.references/</guid><description>( -
)&lt;br/> A list of references for our online discussions.</description></item><item><title>Least Squares, Bootstrap, Maximum Likelihood, and Bayesian</title><link>https://neuronstar.github.io/cpe/02.least-squares-bootstrap-maximum-likelihood-and-bayesian/</link><pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate><project:when_start>2020-12-12T14:30:00</project:when_start><project:when_end>2020-12-12T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/02.least-squares-bootstrap-maximum-likelihood-and-bayesian/</guid><description>(<time>2020-12-12T14:30:00</time> -<time>2020-12-12T16:00:00</time>)&lt;br/> Least squares, bootstrap, maximum likelihood, and maximum posterior leads to the same results in many cases.</description></item><item><title>Conditional Probability and Bayes</title><link>https://neuronstar.github.io/cpe/01.conditional-probability-and-bayes/</link><pubDate>Wed, 18 Nov 2020 00:00:00 +0000</pubDate><project:when_start>2020-11-28T14:30:00</project:when_start><project:when_end>2020-11-28T16:00:00</project:when_end><guid>https://neuronstar.github.io/cpe/01.conditional-probability-and-bayes/</guid><description>(<time>2020-11-28T14:30:00</time> -<time>2020-11-28T16:00:00</time>)&lt;br/> The Bayesian view of probability is quite objective and also more general than the frequentist&amp;rsquo;s view. It doesn&amp;rsquo;t rely on repeatition of events.</description></item></channel></rss>