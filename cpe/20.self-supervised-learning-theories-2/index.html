<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.68.3"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Self-supervised Learning: Theories (Part 2) | NeuronStar | NeuronStar</title><meta name=description content="Theories of self-supervised learning"><meta name=author content><meta property="og:title" content="Self-supervised Learning: Theories (Part 2)"><meta property="og:description" content="Theories of self-supervised learning"><meta property="og:type" content="article"><meta property="og:url" content="https://neuronstar.github.io/cpe/20.self-supervised-learning-theories-2/"><meta property="article:published_time" content="2021-08-26T00:00:00+00:00"><meta property="article:modified_time" content="2021-08-26T00:00:00+00:00"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-61051776-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link rel=canonical href=https://neuronstar.github.io/cpe/20.self-supervised-learning-theories-2/><link rel="shortcut icon" type=image/png href=/logos/logo-square.png><link rel=stylesheet href=/css/bulma.css><link rel=stylesheet href=/css/bulma-divider.min.css><link rel=stylesheet href=/assets/css/bulma-ribbon.min.css><link rel=stylesheet href=/assets/css/tooltip.css><link rel=stylesheet href=https://unpkg.com/bulmaswatch/united/bulmaswatch.min.css><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=/css/blog-post.css><link rel=stylesheet href=/css/code-highlighting/dark.css><link rel=stylesheet href=/css/custom.css><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],tags:'ams',processEscapes:true,processEnvironments:true},options:{skipHtmlTags:['script','noscript','style','textarea','pre']},svg:{fontCache:'global'}};window.addEventListener('load',(event)=>{document.querySelectorAll("mjx-container").forEach(function(x){x.parentElement.classList+='has-jax'})});</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>mermaid.initialize({startOnLoad:true});</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css integrity="sha512-9usAa10IRO0HhonpyAIVpjrylPvoDwiPUiKdWk5t3PyolY1cOd4DSE0Ga+ri4AuTroPR5aQvXU9xC6qOPnzFeg==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/js/all.min.js integrity="sha512-yFjZbTYRCJodnuyGlsKamNE/LlEaEAxSUDe5+u61mV8zzqJVFOH7TnULE2/PP/l5vKWpUNnF4VGVkXh3MjgLsg==" crossorigin=anonymous referrerpolicy=no-referrer></script></head><body><header><nav class="navbar is-transparent"><div class=navbar-brand><a class=navbar-item href=/><img src=/images/logos/logo.png alt=NeuronStar height=28 style=margin-right:.5em> NeuronStar</a><div class="navbar-burger burger" style=color:#000 data-target=navMenu><span></span><span></span><span></span></div></div><div class=navbar-menu id=navMenu><div class=navbar-start><div class="navbar-item has-dropdown is-hoverable"><a href=/projects class=navbar-link>Groups</a><div class=navbar-dropdown><a href=https://neuronstar.github.io/cpe/ class=navbar-item>Conditional Probability Estimation</a>
<a href=https://neuronstar.github.io/snm/ class=navbar-item>Spiking Neuron Models Reading Club</a>
<a href=https://neuronstar.github.io/esl/ class=navbar-item>The Elements of Statistical Learning</a></div></div><div class="navbar-item has-dropdown is-hoverable"></div></div><span class=navbar-burger><span></span><span></span><span></span></span><div class=navbar-end><div class=navbar-item><a class=navbar-item href=/about/>About</a>
<a class=navbar-item href=https://neuronstar.github.io/cpe-docs>CPE Docs</a>
<a class=navbar-item href=https://github.com/neuronstar/seminar-discussions/discussions/categories/papers-please>Propose New Papers</a>
<a class=navbar-item href=https://github.com/kausalflow/community/discussions/categories/2-journal-club-machine-learning>Community</a>
<a class=navbar-item target=blank href=https://github.com/neuronstar><span class=icon><i class="fab fa-github"></i></span></a></div></div></div></nav><script>document.addEventListener('DOMContentLoaded',()=>{const $navbarBurgers=Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'),0);if($navbarBurgers.length>0){$navbarBurgers.forEach(el=>{el.addEventListener('click',()=>{const target=el.dataset.target;const $target=document.getElementById(target);console.log("target",target)
console.log("$target",$target)
el.classList.toggle("is-active");console.log("active el",el)
console.log("active $target",$target)});});}});</script></header><main><div class=container itemscope itemtype=http://schema.org/BlogPosting><meta itemprop=name content="Self-supervised Learning: Theories (Part 2)"><meta itemprop=description content="Theories of self-supervised learning"><meta itemprop=datePublished content="2021-08-26T00:00:00+00:00"><meta itemprop=dateModified content="2021-08-26T00:00:00+00:00"><meta itemprop=wordCount content="34"><meta itemprop=keywords content="Self-supervised Learning,"><section class=section><div class=container><article class=post><header class=post-header><nav class="breadcrumb has-succeeds-separator is-small" aria-label=breadcrumbs><ul><li><a href=https://neuronstar.github.io/>NeuronStar</a></li><li><a href=https://neuronstar.github.io/cpe/>Conditional Probability Estimation</a></li><li class=active><a href=https://neuronstar.github.io/cpe/20.self-supervised-learning-theories-2/>Self-supervised Learning: Theories (Part 2)</a></li></ul></nav><h1 class="post-title has-text-centered is-size-1" itemprop="name headline">Self-supervised Learning: Theories (Part 2)</h1><h2 class="title is-6 has-text-centered"><i class="fas fa-tags" style=margin-right:.5em></i><a href=/tags/self-supervised-learning><span class="tag is-warning is-small is-light">#Self-supervised Learning</span></a></h2></header><div class=columns><div class="column is-8"><div class=is-divider data-content=ARTICLE></div><div class="content blog-post section" itemprop=articleBody><p>We will dive deep into Section 6 of the paper <a href=https://arxiv.org/abs/2006.08218>arXiv:2006.08218</a>. Here are a few topics to be explored.</p><ul><li>InfoGAN objective;</li><li>Positive and negative samples in loss function (InfoNCE);</li><li>Uniformity in constrastive loss;</li><li>JS-divergence.</li></ul></div><p><div class="has-text-right is-size-7"><span class=icon><i class="fas fa-pencil-alt"></i></span>Planted: <time datetime=2021-08-26T00:00:00+00:00>2021-08-26</time>
by <span itemprop=author>NeuronStar</span>;</div></p><div class=is-divider></div><nav class="pagination is-centered" role=navigation aria-label=pagination><a href="https://neuronstar.github.io/cpe/19.self-supervised-learning-theories-1/?ref=footer" class=pagination-previous>« Self-supervised Learning: Theories (Part 1)</a>
<a class=pagination-next href="https://neuronstar.github.io/cpe/21.gnn-basics/?ref=footer">Graph Neural Networks: Basics »</a></nav></div><div class="column is-4"><div class=is-divider data-content=WHEN&WHERE></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><span style=display:block><i class="fas fa-calendar-day"></i>: 2021-09-11T14:30:00 - 2021-09-11T16:00:00 (CET)</span>
<span style=display:block><i class="fas fa-comment-alt"></i>: Lark</span>
<span style=display:block><i class="fas fa-project-diagram"></i>: More details on page
<a href=https://neuronstar.github.io/projects/conditional-probability-estimation/ class=has-text-warning>Conditional Probability Estimation</a><div id=add-to-calendar></div></p></div></div></article></div><style>#TableOfContents>ul{list-style-type:lower-greek;padding-left:0}#TableOfContents>ul>li ul{list-style-type:none;padding-left:1em}</style><script>const el=document.querySelector('details summary')
el.onclick=()=>{(function(l,o,a,d,e,r){e=o.createElement(a),r=o.getElementsByTagName(a)[0];e.async=1;e.src=d;r.parentNode.insertBefore(e,r)})(window,document,'script','/js/smoothscroll.js');el.onclick=null}
document.querySelectorAll('#TableOfContents a').forEach(link=>{link.addEventListener('click',()=>{document.querySelector(link.href.slice(link.href.indexOf('#'))).scrollIntoView({behavior:'smooth'})})})</script><div class=is-divider data-content=REFERENCES></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>References:</strong><br><ol><li class=has-text-weight-bold><a href=http://arxiv.org/abs/2006.08218 style=text-decoration:none>Liu X, Zhang F, Hou Z, Wang Z, Mian L, Zhang J, et al. Self-supervised Learning: Generative or Contrastive. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2006.08218</a></li><li class=has-text-weight-bold><a href=http://arxiv.org/abs/2005.10242 style=text-decoration:none>Wang T, Isola P. Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere. arXiv [cs.LG]. 2020. Available: http://arxiv.org/abs/2005.10242</a></li><li class=has-text-weight-bold><a href=http://arxiv.org/abs/2003.14323 style=text-decoration:none>Newell A, Deng J. How Useful is Self-Supervised Pretraining for Visual Tasks? arXiv [cs.CV]. 2020. Available: http://arxiv.org/abs/2003.14323</a></li><li class=has-text-weight-bold><a href=http://arxiv.org/abs/1907.13625 style=text-decoration:none>Tschannen M, Djolonga J, Rubenstein PK, Gelly S, Lucic M. On Mutual Information Maximization for Representation Learning. arXiv [cs.LG]. 2019. Available: http://arxiv.org/abs/1907.13625</a></li><li class=has-text-weight-bold><a href=http://arxiv.org/abs/1807.03748 style=text-decoration:none>van den Oord A, Li Y, Vinyals O. Representation learning with Contrastive Predictive Coding. arXiv [cs.LG]. 2018. Available: http://arxiv.org/abs/1807.03748</a></li><li class=has-text-weight-bold><a href=http://arxiv.org/abs/1606.03657 style=text-decoration:none>Chen X, Duan Y, Houthooft R, Schulman J, Sutskever I, Abbeel P. InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets. arXiv [cs.LG]. 2016. Available: http://arxiv.org/abs/1606.03657</a></li><li class=has-text-weight-bold><a href=http://arxiv.org/abs/1606.00709 style=text-decoration:none>Nowozin S, Cseke B, Tomioka R. f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization. arXiv [stat.ML]. 2016. Available: http://arxiv.org/abs/1606.00709</a></li></ol></p></div></div></article></div><div class=is-divider data-content=CONNECTUME></div><div class="box is-size-7"><article class=media><div class=media-content><div class=content><p><strong>Current Ref:</strong><br><ul><li style=list-style:none><span class="tag is-primary is-light has-text-weight-bold">cpe/20.self-supervised-learning-theories-2.md</span></li></ul></p></div></div></article></div><div id=comments class=is-divider data-content=COMMENTS></div><script src=https://giscus.app/client.js data-repo=neuronstar/neuronstar.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkzMjY1MDkyMg==" data-category=Comments data-category-id=DIC_kwDOAfI2qs4B-wVl data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=1 data-theme=light crossorigin=anonymous async></script></div></div></article></div></section></div><div class=navtools><a class="button is-primary is-light is-outlined" alt="Edit this page" href=https://github.com/neuronstar/neuronstar.github.io/edit/master/content/cpe/20.self-supervised-learning-theories-2.md target=blank style=position:fixed;bottom:20px;right:10px;border-radius:9999px;width:35px;height:35px><i class="fas fa-pencil-alt"></i></a><a class="button is-primary is-light is-outlined" href=#comments alt=Comments style=position:fixed;bottom:60px;right:10px;border-radius:9999px;width:35px;height:35px><i class="far fa-comments"></i></a><a class="button is-primary is-light is-outlined" href=#connectome alt=Connectome style=position:fixed;bottom:100px;right:10px;border-radius:9999px;width:35px;height:35px><i class="fa-solid fa-brain"></i></a></div></main><footer><footer class=footer><div class=container><div class="content has-text-centered"><p>Created and maintained by <a href=https://neuronstar.github.io>NeuronStar</a>.
Acknowledgement: <a href=https://gohugo.io/>Hugo</a>,
<a href=https://themes.gohugo.io/bulma/>Bulma</a>, <a href=https://kausalflow.com>KausalFlow</a>.
<strong>love</strong>.<br><a class=tag href=/index.xml>Feed</a>
<a class=tag href=/data.json>JSON Data</a></p></div></div></footer><link rel=stylesheet href=/assets/add-to-calendar-buttons/add-to-calendar.css><script src=/assets/add-to-calendar-buttons/add-to-calendar.min.js></script><script>var myCalendar=addToCalendar({options:{class:'event-calendar-add-button',id:'event-calendar-add'},data:{title:'Self-supervised Learning: Theories (Part 2)',start:new Date('2021-09-11T14:30:00'),end:new Date('2021-09-11T16:00:00'),timezone:'CET',address:'Lark',description:'We will dive deep into Section 6 of the paper arXiv:2006.08218. Here are a few topics to be explored.\nInfoGAN objective; Positive and negative samples in loss function (InfoNCE); Uniformity in constrastive loss; JS-divergence.'}});document.querySelector('#add-to-calendar').appendChild(myCalendar);</script></footer><script async type=text/javascript src=/js/bulma.js></script><script type=application/json class=js-hypothesis-config>{"openSidebar":false,"theme":"clean","enableExperimentalNewNoteButton":true,"showHighlights":true}</script><script async src=https://hypothes.is/embed.js></script></body></html>