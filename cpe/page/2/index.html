<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.68.3"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Conditional Probability Estimation | NeuronStar | NeuronStar</title><meta name=description content="An online discussion group on the topic Conditional Probability Estimation"><meta name=robots content="noindex"><meta name=author content="NeuronStar"><meta property="og:title" content="Conditional Probability Estimation"><meta property="og:description" content="An online discussion group on the topic Conditional Probability Estimation"><meta property="og:type" content="website"><meta property="og:url" content="https://neuronstar.github.io/cpe/"><meta property="og:updated_time" content="2021-08-26T00:00:00+00:00"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-61051776-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link href=https://neuronstar.github.io/cpe/index.xml rel=alternate type=application/rss+xml title=NeuronStar><link rel=canonical href=https://neuronstar.github.io/cpe/><link rel="shortcut icon" type=image/png href=/logos/logo-square.png><link rel=stylesheet href=/css/bulma.css><link rel=stylesheet href=/css/bulma-divider.min.css><link rel=stylesheet href=/assets/css/bulma-ribbon.min.css><link rel=stylesheet href=/assets/css/tooltip.css><link rel=stylesheet href=https://jenil.github.io/bulmaswatch/united/bulmaswatch.min.css><link rel=stylesheet href=/css/custom.css><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],tags:'ams',processEscapes:true,processEnvironments:true},options:{skipHtmlTags:['script','noscript','style','textarea','pre']},svg:{fontCache:'global'}};window.addEventListener('load',(event)=>{document.querySelectorAll("mjx-container").forEach(function(x){x.parentElement.classList+='has-jax'})});</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><script>mermaid.initialize({startOnLoad:true});</script><script src=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/js/all.min.js integrity="sha256-KzZiKy0DWYsnwMF+X1DvQngQ2/FxF7MF3Ff72XcpuPs=" crossorigin=anonymous></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin=anonymous></head><body><header><nav class="navbar is-transparent"><div class=navbar-brand><a class=navbar-item href=/><img src=/images/logos/logo.png alt=NeuronStar height=28 style=margin-right:.5em> NeuronStar</a><div class="navbar-burger burger" style=color:#000 data-target=navMenu><span></span><span></span><span></span></div></div><div class=navbar-menu id=navMenu><div class=navbar-start><div class="navbar-item has-dropdown is-hoverable"><a href=/projects class=navbar-link>Groups</a><div class=navbar-dropdown><a href=https://neuronstar.github.io/cpe/ class=navbar-item>Conditional Probability Estimation</a>
<a href=https://neuronstar.github.io/snm/ class=navbar-item>Spiking Neuron Models Reading Club</a>
<a href=https://neuronstar.github.io/esl/ class=navbar-item>The Elements of Statistical Learning</a></div></div></div><span class=navbar-burger><span></span><span></span><span></span></span><div class=navbar-end><div class=navbar-item><a class=navbar-item target=blank href=https://github.com/neuronstar><span class=icon><i class="fab fa-github"></i></span></a></div></div></div></nav><script>document.addEventListener('DOMContentLoaded',()=>{const $navbarBurgers=Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'),0);if($navbarBurgers.length>0){$navbarBurgers.forEach(el=>{el.addEventListener('click',()=>{const target=el.dataset.target;const $target=document.getElementById(target);el.classList.toggle('is-active');$target.classList.toggle('is-active');});});}});</script></header><main><section><div class="hero is-primary is-medium"><div class=hero-body><div class="container has-text-left"><h1 class="title is-1">Conditional Probability Estimation</h1><h2 class="subtitle is-4">An online discussion group on the topic Conditional Probability Estimation</h2><h3 class="title is-5" style=margin-top:2em><a href=https://neuronstar.github.io/projects/conditional-probability-estimation/ class=has-text-warning><i class="fas fa-link"></i>Introduction: Conditional Probability Estimation</a></h3></div></div></div></section><div class="columns is-fullheight"><div class=column><section class="hero is-default is-bold"><div class=hero-body><div class=container><nav class="breadcrumb has-succeeds-separator is-small" aria-label=breadcrumbs><ul><li><a href=https://neuronstar.github.io/>NeuronStar</a></li><li class=active><a href=https://neuronstar.github.io/cpe/>Conditional Probability Estimation</a></li></ul></nav><div class="columns is-multiline is-variable is-1-mobile is-0-tablet is-3-desktop is-8-widescreen is-2-fullhd is-desktop"><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><sup>9</sup> <a href=https://neuronstar.github.io/cpe/09.summary-of-generative-models/ itemprop=headline>Summary of Generative Models</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2021-02-27T00:00:00+00:00>2021-02-27</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/vae style=margin-right:.5em><span class="tag is-warning is-small is-light">#VAE</span></a>
<a href=/tags/flow style=margin-right:.5em><span class="tag is-warning is-small is-light">#Flow</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://arxiv.org/abs/2103.04922>Deep Generative Modelling: A Comparative Review of VAEs, GANs, Normalizing Flows, Energy-Based and Autoregressive Models</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary:</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-list-alt"></i>Pages: 21</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><sup>8</sup> <a href=https://neuronstar.github.io/cpe/08.maf/ itemprop=headline>MAF: how is MADE being used</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2021-02-27T00:00:00+00:00>2021-02-27</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/vae style=margin-right:.5em><span class="tag is-warning is-small is-light">#VAE</span></a>
<a href=/tags/flow style=margin-right:.5em><span class="tag is-warning is-small is-light">#Flow</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://arxiv.org/abs/1705.07057>Masked Autoregressive Flow for Density Estimation</a></span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://www.tensorflow.org/probability/api_docs/python/tfp/bijectors/MaskedAutoregressiveFlow>Tensorflow Documentation</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: We discussed MAF (arXiv:1705.07057v4) last time: The paper did not explain how exactly is MADE being used to update the shift and logscale.
We will use the tensorflow implementation of MAF to probe the above question. Here is the link to the relevant documentation: https://www.tensorflow.org/probability/api_docs/python/tfp/bijectors/MaskedAutoregressiveFlow
Topics Refer to references.
Notes 1310.8499_notes.pdf</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-list-alt"></i>Pages: 21</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><sup>7</sup> <a href=https://neuronstar.github.io/cpe/07.made/ itemprop=headline>MADE: Masked Autoencoder for Distribution Estimation</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2021-02-27T00:00:00+00:00>2021-02-27</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/vae style=margin-right:.5em><span class="tag is-warning is-small is-light">#VAE</span></a>
<a href=/tags/flow style=margin-right:.5em><span class="tag is-warning is-small is-light">#Flow</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://arxiv.org/abs/1502.03509>MADE: Masked Autoencoder for Distribution Estimation</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Topics Refer to references.
Notes 1310.8499_notes.pdf</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-list-alt"></i>Pages: 21</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><sup>6</sup> <a href=https://neuronstar.github.io/cpe/06.deep-autoregressive-networks/ itemprop=headline>Deep AutoRegressive Networks</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2021-02-13T00:00:00+00:00>2021-02-13</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/autoregressive style=margin-right:.5em><span class="tag is-warning is-small is-light">#AutoRegressive</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://arxiv.org/abs/1310.8499>Gregor, K., Danihelka, I., Mnih, A., Blundell, C., & Wierstra, D. (2014). Deep autoregressive networks. 31st International Conference on Machine Learning, ICML 2014, 4, 2991–3000.</a></span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://deepgenerativemodels.github.io/notes/autoregressive/>Autoregressive models</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Topics Refer to references.
Notes 1310.8499_notes.pdf</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-list-alt"></i>Pages: 21</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><sup>5</sup> <a href=https://neuronstar.github.io/cpe/05.normalizing-flow-review/ itemprop=headline>Review of Normalizing Flow</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2021-01-30T00:00:00+00:00>2021-01-30</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/normalizing-flow style=margin-right:.5em><span class="tag is-warning is-small is-light">#Normalizing Flow</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://doi.org/10.1109/TPAMI.2020.2992934>Kobyzev, I., Prince, S., & Brubaker, M. (2020). Normalizing Flows: An Introduction and Review of Current Methods. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1–1.</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Topics Normalizing flow Applications of normalizing flow Methods of normalizing flow Problems of normalizing flow</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-list-alt"></i>Pages: 21</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><sup>4</sup> <a href=https://neuronstar.github.io/cpe/04.variational-inference-normalizing-flow/ itemprop=headline>Variantional Inference Normalizing Flow</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2021-01-16T00:00:00+00:00>2021-01-16</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/variational-inference style=margin-right:.5em><span class="tag is-warning is-small is-light">#Variational Inference</span></a>
<a href=/tags/normalizing-flow style=margin-right:.5em><span class="tag is-warning is-small is-light">#Normalizing Flow</span></a>
<a href=/tags/bayesian style=margin-right:.5em><span class="tag is-warning is-small is-light">#Bayesian</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://doi.org/978-0387-31073-2>Christpher M. Bishop. (2006). Pattern Recognition and Machine Learning.</a></span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=http://arxiv.org/abs/1505.05770>Rezende, D. J., & Mohamed, S. (2015). Variational Inference with Normalizing Flows.</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Topics Variational Inference Normalizing Flow Variational Inference with Normalizing Flows</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-list-alt"></i>Pages: 21</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><sup>3</sup> <a href=https://neuronstar.github.io/cpe/03.em-methods/ itemprop=headline>EM Methods</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2021-01-02T00:00:00+00:00>2021-01-02</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/maximum-likelihood style=margin-right:.5em><span class="tag is-warning is-small is-light">#Maximum Likelihood</span></a>
<a href=/tags/bayesian style=margin-right:.5em><span class="tag is-warning is-small is-light">#Bayesian</span></a>
<a href=/tags/sampling style=margin-right:.5em><span class="tag is-warning is-small is-light">#Sampling</span></a>
<a href=/tags/gaussian-mixture style=margin-right:.5em><span class="tag is-warning is-small is-light">#Gaussian Mixture</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://web.stanford.edu/~hastie/ElemStatLearn/>Trevor Hastie, Robert Tibshirani, J. F. (2004). The Elements of Statistical Learning (Vol. 99, Issue 466). Springer Science & Business Media.</a></span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://doi.org/978-0387-31073-2>Christpher M. Bishop. (2006). Pattern Recognition and Machine Learning.</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: EM method, expectation-maximization algorithm, is an inspiring iterative method to find the log-likelihood by introducing some intermediate variable such as responsibility.</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-list-alt"></i>Pages: 21</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><sup>2</sup> <a href=https://neuronstar.github.io/cpe/02.least-squares-bootstrap-maximum-likelihood-and-bayesian/ itemprop=headline>Least Squares, Bootstrap, Maximum Likelihood, and Bayesian</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2020-12-12T00:00:00+00:00>2020-12-12</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/bayesian style=margin-right:.5em><span class="tag is-warning is-small is-light">#Bayesian</span></a>
<a href=/tags/least-squares style=margin-right:.5em><span class="tag is-warning is-small is-light">#Least Squares</span></a>
<a href=/tags/bootstrap style=margin-right:.5em><span class="tag is-warning is-small is-light">#Bootstrap</span></a>
<a href=/tags/maximum-likelihood style=margin-right:.5em><span class="tag is-warning is-small is-light">#Maximum Likelihood</span></a>
<a href=/tags/bayesian style=margin-right:.5em><span class="tag is-warning is-small is-light">#Bayesian</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://web.stanford.edu/~hastie/ElemStatLearn/>Trevor Hastie, Robert Tibshirani, J. F. (2004). The Elements of Statistical Learning (Vol. 99, Issue 466). Springer Science & Business Media.</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Relation and difference between different methods in regression</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-list-alt"></i>Pages: 21</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div><div class="column is-half is-multiline" itemscope itemtype=http://schema.org/CreativeWork><h1 class=blog-timestamp></h1><h1 class=title><sup>1</sup> <a href=https://neuronstar.github.io/cpe/01.conditional-probability-and-bayes/ itemprop=headline>Conditional Probability and Bayes</a></h1><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-calendar-alt"></i>Published: <time datetime=2020-11-18T00:00:00+00:00>2020-11-18</time></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-hashtag" aria-hidden=true></i>Tags:<div class="tags is-small" style=display:inline><a href=/tags/bayesian style=margin-right:.5em><span class="tag is-warning is-small is-light">#Bayesian</span></a>
<a href=/tags/bayess-theorem style=margin-right:.5em><span class="tag is-warning is-small is-light">#Bayes's Theorem</span></a>
<a href=/tags/conditional-probability style=margin-right:.5em><span class="tag is-warning is-small is-light">#Conditional Probability</span></a></div></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="fa fa-paperclip" aria-hidden=true></i>References:</span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://web.stanford.edu/~hastie/ElemStatLearn/>Trevor Hastie, Robert Tibshirani, J. F. (2004). The Elements of Statistical Learning (Vol. 99, Issue 466). Springer Science & Business Media.</a></span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://datumorphism.leima.is/wiki/pattern-mining/association-rules/>Association Rules</a></span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://en.wikipedia.org/wiki/Bayes%27_theorem#/media/File:Bayes%27_Theorem_2D.svg>Bayes' theorem @ Wikipedia</a></span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://doi.org/10.1016/C2013-0-19397-X>Ross, S. M. (2014). Introduction to Probability and Statistics for Engineers and Scientists. Elsevier.</a></span>
<span style=display:block;font-size:90%;padding-left:1em>- <a href=https://datumorphism.leima.is/wiki/machine-learning/bayesian/naive-bayesian/>Naive Bayes</a></span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-star"></i>Summary: Skeleton notes for conditional probability and Bayes' theorem</span></div><div style=margin-left:2em><span style=display:block;font-size:90%><i class="far fa-list-alt"></i>Pages: 21</span></div></div><div class=is-divider style="border-top:.05rem dashed #dbdbdb!important;margin:1em 0!important"></div></div></div><br><div class=container><nav class="pagination has-text-centered" role=navigation aria-label=pagination><a class="button is-primary" href=/cpe/><span class="icon is-small"><i class="fa fa-angle-double-left"></i></span><span>Previous</span></a>
<a class="button is-outlined is-primary">Page 2 of 2</a></nav></div></div></section></div></div></main><footer><footer class=footer><div class=container><div class="content has-text-centered"><p>Created and maintained by <a href=https://neuronstar.github.io>NeuronStar</a>.
Acknowledgement: <a href=https://gohugo.io/>Hugo</a>,
<a href=https://themes.gohugo.io/bulma/>Bulma</a>, <a href=https://kausalflow.com>KausalFlow</a>.
<strong>love</strong>.<br><a class=tag href=/index.xml>Feed</a>
<a class=tag href=/data.json>JSON Data</a></p></div></div></footer></footer><script async type=text/javascript src=/js/bulma.js></script></body></html>